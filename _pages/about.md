---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a master student in Computer Science at Tongji University, expected to graduate in March 2026. My research primarily focuses on **multimodal intelligence**, including **multimodal retrieval and generation**, **reasoning with multimodal large language models**, and **their interaction in distributed environments**. My work aims to advance the capability of AI systems to understand and reason across multiple modalities while addressing challenges such as privacy preservation, trustworthy reasoning, and model efficiency.

## üì¢ Actively Seeking 2026 Fall PhD Positions

<span style="color:red;">I am actively seeking PhD opportunities starting Fall 2026. I would be thrilled to work with prospective advisors and research groups. Please feel free to contact me.</span>

## üìñ Educations
- 2023.09 - 2026.03, Master, Tongji University, Shanghai, China.
- 2019.09 - 2023.06, Undergraduate, Dalian Maritime University, Dalian, China.


<!-- --------------------------------------------------------------- -->


## üìù Selected Publications 


<!-- <div class='paper-box'><div class='paper-box-image'><div><img src='images/valik.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning (ICCV 2025)** \\
**Junming Liu**, S Meng, Y Gao, S Mao, P Cai, G Yan, Y Chen, Z Bian, D Wang, B Shi


<div class='paper-box'><div class='paper-box-image'><div><img src='images/hmrag.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->

<!-- **HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation (ACM MM 2025)** \\
P Liu, X Liu, R Yao, **Junming Liu**, S Meng, D Wang, J Ma. -->


<!-- Paper 1 -->
<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 0 0 40%; padding-right: 15px;">
    <img src="images/valik.png" alt="sym" style="width: 100%; border-radius: 8px;">
  </div>
  <div style="flex: 1;">
    <strong>Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning (ICCV 2025)</strong><br>
    <b>Junming Liu</b>, S Meng, Y Gao, S Mao, P Cai, G Yan, Y Chen, Z Bian, D Wang, B Shi
  </div>
</div>

<!-- Paper 2 -->
<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 0 0 40%; padding-right: 15px;">
    <img src="images/hmrag.jpg" alt="sym" style="width: 100%; border-radius: 8px;">
  </div>
  <div style="flex: 1;">
    <strong>HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation (ACM MM 2025)</strong><br>
    P Liu, X Liu, R Yao, <b>Junming Liu</b>, S Meng, D Wang, J Ma.
  </div>
</div>


For a complete list of publications, please refer to my [Google Scholar profile](https://scholar.google.com.hk/citations?user=U8CS_BwAAAAJ&hl=en-US).


<!-- --------------------------------------------------------------- -->


## Professional Service

I serve as a reviewer for **ICME, SMC, and AAAI**, contributing to the peer-review process in the fields of computer vision, multimodal AI, and machine learning.

## Skills & Tools

- **Programming & Frameworks:** Python, PyTorch, Distributed Training, Linux, C/C++, Java  
- **Languages:** Chinese (native), English (IELTS 7.0), Japanese, German  
- **Specialized Knowledge:** Multimodal foundation models, medical image analysis, knowledge graph construction, PEFT, diffusion models  