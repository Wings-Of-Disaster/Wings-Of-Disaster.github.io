---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a master student in Computer Science at Tongji University, expected to graduate in March 2026. My research primarily focuses on **Multimodal Intelligence**, including **Multimodal Retrieval and Generation**, **Multimodal Large Language Models**, and **Multi-Agent Interaction**. My work aims to advance the capability of AI systems to understand and reason across multiple modalities while addressing challenges such as privacy preservation, trustworthiness, and model efficiency.

Recently, my work has been centered around the following areas:
- <span style="color: #00008B;">**Retrieval-Augmented Generation and Memory Agents**</span>
- <span style="color: #00008B;">**Post-training of Multimodal Large Language Models**</span>

## ğŸ“¢ Actively Seeking 2026 Fall PhD Positions

<span style="color:red;">I am actively seeking PhD opportunities starting Fall 2026. I would be thrilled to work with prospective advisors and research groups. Please feel free to contact me.</span>

<!-- ## Educations

- 2023.09 - 2026.03, Master, Tongji University, Shanghai, China.
- 2019.09 - 2023.06, Undergraduate, Dalian Maritime University, Dalian, China. -->

<!-- --------------------------------------------------------------- -->

## News

<div class="service-list news-list">
  <ul>
    <li><strong>[01/2026]</strong> Our paper DMM has been accepted at ICASSP 2026! ğŸ‰ğŸ‰</li>
    <li><strong>[01/2026]</strong> Our paper AMID has been accepted at WWW 2026! ğŸ‰ğŸ‰</li>
    <li><strong>[11/2025]</strong> Our paper <a href="https://arxiv.org/abs/2511.17068" style="color: #00008B;">ReBrain</a> has been accepted at WACV 2026! ğŸ‰ğŸ‰</li>
    <li><strong>[08/2025]</strong> Our paper <a href="https://link.springer.com/chapter/10.1007/978-981-95-5693-9_5" style="color: #00008B;">COGO</a> has been accepted by PRCV 2025! ğŸ‰ğŸ‰</li>
    <li><strong>[07/2025]</strong> Our paper <a href="https://dl.acm.org/doi/abs/10.1145/3746027.3754761" style="color: #00008B;">HM-RAG</a> has been accepted by ACM MM 2025! ğŸ‰ğŸ‰</li>
    <li><strong>[07/2025]</strong> Our paper <a href="https://openaccess.thecvf.com/content/ICCV2025/html/Liu_Aligning_Vision_to_Language_Annotation-Free_Multimodal_Knowledge_Graph_Construction_for_ICCV_2025_paper.html" style="color: #00008B;">VaLiK</a> has been accepted at ICCV 2025! ğŸ‰ğŸ‰</li>
    <li><strong>[01/2025]</strong> Joined Shanghai Artificial Intelligence Laboratory as an Intern! âš¡ï¸âš¡ï¸</li>
  </ul>
</div>
<br>

## Selected Publications 

<!-- <div class='paper-box'><div class='paper-box-image'><div><img src='images/valik.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning (ICCV 2025)** \\
**Junming Liu**, S Meng, Y Gao, S Mao, P Cai, G Yan, Y Chen, Z Bian, D Wang, B Shi

<div class='paper-box'><div class='paper-box-image'><div><img src='images/hmrag.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1"> -->

<!-- **HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation (ACM MM 2025)** \\
P Liu, X Liu, R Yao, **Junming Liu**, S Meng, D Wang, J Ma. -->

<!-- Paper 1 -->
<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 0 0 40%; padding-right: 15px;">
    <img src="images/valik.png" alt="sym" style="width: 100%; border-radius: 8px;">
  </div>
  <div style="flex: 1;">
    <strong>Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph Construction for Enhanced LLMs Reasoning (<span style="color: darkred;">ICCV 2025</span>)</strong><br>
    <b>Junming Liu</b>, S Meng, Y Gao, S Mao, P Cai, G Yan, Y Chen, Z Bian, D Wang, B Shi
  </div>
</div>

<!-- Paper 2 -->
<div style="display: flex; align-items: flex-start; margin-bottom: 30px;">
  <div style="flex: 0 0 40%; padding-right: 15px;">
    <img src="images/hmrag.jpg" alt="sym" style="width: 100%; border-radius: 8px;">
  </div>
  <div style="flex: 1;">
    <strong>HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation (<span style="color: darkred;">ACM MM 2025</span>)</strong><br>
    P Liu, X Liu, R Yao, <b>Junming Liu</b>, S Meng, D Wang, J Ma.
  </div>
</div>

For a complete list of publications, please refer to my [publications page](https://wings-of-disaster.github.io/publications/).

<!-- --------------------------------------------------------------- -->

## Internships
- 2023.06 - 2023.09, Embedded Engineer, Shanghai NIO Automobile Co., Ltd.
  - Controlled steering and braking systems under tire blowout scenarios using image and radar data to prevent rollover and loss of control.

- 2025.01 - Present, Research Scientist, Shanghai Artificial Intelligence Laboratory
  - Conducted research on multimodal large language models.

## Professional Service

I serve as a reviewer for **ICME, SMC, and AAAI**, contributing to the peer-review process in the fields of computer vision, multimodal AI, and machine learning.

## Skills & Tools

- **Programming & Frameworks:** : C, C++, Python, Java, Go, SQL, Rust, MPI, NCCL, DeepSpeed, DDP, FSDP
- **Languages:** Chinese (native), English (IELTS 7.0), Japanese, German

---

<script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=_JrSqe6LHWABefXTXh3X68RPF-N4Xh31ywvL7P24xAE&cl=ffffff&w=a"></script>